import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

print("=== CARREGANDO DADOS DO VINHO ===")
df = pd.read_csv("../dataset/winequality-red.csv", sep=";")

print("Primeiras 5 linhas do dataset:")
print(df.head())
print(f"\nTamanho do dataset: {df.shape[0]} vinhos com {df.shape[1]} caracterÃ­sticas")

print("\nEstatÃ­sticas descritivas:")
print(df.describe())

print(f"\nValores Ãºnicos na coluna 'quality' (nossa variÃ¡vel alvo):")
print(f"Qualidades possÃ­veis: {sorted(df['quality'].unique())}")
print(f"DistribuiÃ§Ã£o das qualidades:\n{df['quality'].value_counts().sort_index()}")

print(f"\nVerificaÃ§Ã£o de dados faltantes:")
missing_data = df.isnull().sum()
if missing_data.sum() == 0:
    print("âœ“ NÃ£o hÃ¡ dados faltantes no dataset!")
else:
    print(missing_data[missing_data > 0])

print("\n=== ANÃLISE VISUAL DOS DADOS ===")

plt.figure(figsize=(16, 12))

plt.subplot(2, 3, 1)
sns.boxplot(data=df)
plt.xticks(rotation=45)
plt.title('DetecÃ§Ã£o de Outliers')
plt.tight_layout()

plt.subplot(2, 3, 2)
plt.hist(df['quality'], bins=10, edgecolor='black', alpha=0.7, color='skyblue')
plt.xlabel('Qualidade do Vinho')
plt.ylabel('NÃºmero de Vinhos')
plt.title('DistribuiÃ§Ã£o da Qualidade')

plt.subplot(2, 3, 3)
corr = df.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, fmt='.2f', 
            annot_kws={'size': 8}, square=True, linewidths=0.5)
plt.title('Matriz de CorrelaÃ§Ã£o', fontsize=12)
plt.xticks(rotation=45, ha='right', fontsize=9)
plt.yticks(rotation=0, fontsize=9)

plt.subplot(2, 3, 4)
plt.scatter(df['alcohol'], df['quality'], alpha=0.6, color='red')
plt.xlabel('Teor AlcoÃ³lico')
plt.ylabel('Qualidade')
plt.title('Ãlcool vs Qualidade')

plt.subplot(2, 3, 5)
plt.scatter(df['volatile acidity'], df['quality'], alpha=0.6, color='purple')
plt.xlabel('Acidez VolÃ¡til')
plt.ylabel('Qualidade')
plt.title('Acidez VolÃ¡til vs Qualidade')

plt.tight_layout()
plt.savefig('analise_exploratoria.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n=== PRÃ‰-PROCESSAMENTO DOS DADOS ===")

print("Normalizando os dados...")

features = df.drop('quality', axis=1).values
target = df['quality'].values

print(f"CaracterÃ­sticas (X): {features.shape[1]} variÃ¡veis")
print(f"VariÃ¡vel alvo (y): qualidade do vinho")

mean_X = np.mean(features, axis=0)
std_X = np.std(features, axis=0)
X_normalized = (features - mean_X) / std_X

print("âœ“ Dados normalizados!")

print("\n=== DIVISÃƒO DOS DADOS ===")

np.random.seed(42)
n_samples = len(X_normalized)
n_test = int(n_samples * 0.3)
indices = np.random.permutation(n_samples)
test_indices = indices[:n_test]
train_indices = indices[n_test:]

X_train = X_normalized[train_indices]
X_test = X_normalized[test_indices]
y_train = target[train_indices]
y_test = target[test_indices]

print(f"Dados de treino: {X_train.shape[0]} vinhos")
print(f"Dados de teste: {X_test.shape[0]} vinhos")

print("\n=== REGRESSÃƒO LINEAR ===")

def mean_squared_error(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    m, n = X.shape
    X_b = np.c_[np.ones((m, 1)), X]
    theta = np.random.randn(n + 1)
    
    print("Iniciando treinamento...")
    
    for epoch in range(epochs):
        y_pred = X_b.dot(theta)
        error = y_pred - y
        gradients = (2/m) * X_b.T.dot(error)
        theta -= learning_rate * gradients
        
        if epoch % 200 == 0:
            loss = mean_squared_error(y, y_pred)
            print(f"Ã‰poca {epoch:4d}: MSE = {loss:.4f}")
    
    return theta

print("\nTreinando o modelo de regressÃ£o linear...")
theta_final = gradient_descent(X_train, y_train, learning_rate=0.01, epochs=1000)

print(f"\nâœ“ Treinamento concluÃ­do!")

print("\n=== FAZENDO PREDIÃ‡Ã•ES ===")

X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]
y_pred = X_test_b.dot(theta_final)

print(f"PrediÃ§Ãµes feitas para {len(y_test)} vinhos de teste.")

print("\n=== AVALIAÃ‡ÃƒO DO MODELO ===")

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = np.mean(np.abs(y_test - y_pred))
ss_res = np.sum((y_test - y_pred) ** 2)
ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)
r2 = 1 - (ss_res / ss_tot)

print(f"\nğŸ“Š RESULTADOS:")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"RÂ²: {r2:.4f}")

if r2 > 0.7:
    print("â†’ ğŸŸ¢ Modelo muito bom!")
elif r2 > 0.5:
    print("â†’ ğŸŸ¡ Modelo razoÃ¡vel.")
elif r2 > 0.3:
    print("â†’ ğŸŸ  Modelo fraco, mas melhor que o acaso.")
else:
    print("â†’ ğŸ”´ Modelo muito fraco.")

print("\n=== VISUALIZAÃ‡Ã•ES DOS RESULTADOS ===")

plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
plt.scatter(y_test, y_pred, alpha=0.6, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Qualidade Real')
plt.ylabel('Qualidade Predita')
plt.title('PrediÃ§Ãµes vs Realidade')

plt.subplot(2, 3, 2)
residuals = y_test - y_pred
plt.scatter(y_pred, residuals, alpha=0.6, color='green')
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('PrediÃ§Ãµes')
plt.ylabel('ResÃ­duos')
plt.title('AnÃ¡lise de ResÃ­duos')

plt.subplot(2, 3, 3)
plt.hist(residuals, bins=20, edgecolor='black', alpha=0.7, color='orange')
plt.xlabel('ResÃ­duos')
plt.ylabel('FrequÃªncia')
plt.title('DistribuiÃ§Ã£o dos Erros')

plt.subplot(2, 3, 4)
feature_names = df.drop('quality', axis=1).columns
weights = theta_final[1:]
plt.barh(range(len(weights)), weights)
plt.yticks(range(len(weights)), feature_names)
plt.xlabel('Peso no Modelo')
plt.title('ImportÃ¢ncia das CaracterÃ­sticas')

plt.subplot(2, 3, 5)
sample_indices = np.random.choice(len(y_test), 20, replace=False)
x_pos = range(len(sample_indices))
plt.bar([x - 0.2 for x in x_pos], y_test[sample_indices], width=0.4, 
        label='Real', alpha=0.7, color='blue')
plt.bar([x + 0.2 for x in x_pos], y_pred[sample_indices], width=0.4, 
        label='Predito', alpha=0.7, color='red')
plt.xlabel('Amostras')
plt.ylabel('Qualidade')
plt.title('ComparaÃ§Ã£o: 20 Amostras')
plt.legend()

plt.tight_layout()
plt.savefig('resultados_regressao_linear.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"\n" + "="*60)
print(f"RESUMO FINAL")
print(f"="*60)

print(f"\nğŸ“Š DADOS:")
print(f"   â€¢ {df.shape[0]} vinhos analisados")
print(f"   â€¢ {df.shape[1]-1} caracterÃ­sticas quÃ­micas")

print(f"\nğŸ“ˆ PERFORMANCE:")
print(f"   â€¢ RÂ² = {r2:.3f} ({r2:.1%} da variaÃ§Ã£o explicada)")
print(f"   â€¢ Erro mÃ©dio = {mae:.2f} pontos de qualidade")
print(f"   â€¢ RMSE = {rmse:.2f}")

print(f"\nğŸ” CARACTERÃSTICAS MAIS IMPORTANTES:")
feature_importance = list(zip(feature_names, theta_final[1:]))
feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)

for i, (feature, weight) in enumerate(feature_importance[:5]):
    direction = "aumenta" if weight > 0 else "diminui"
    print(f"   {i+1}. {feature}: {direction} a qualidade (peso: {weight:.3f})")

print(f"\n" + "="*60)

print(f"\n=== EXPLICAÃ‡ÃƒO DOS RESULTADOS ===")

print(f"\nğŸ” ANÃLISE DOS GRÃFICOS:")

print(f"\n1. PREDIÃ‡Ã•ES vs REALIDADE:")
if r2 > 0.5:
    print(f"   âœ… Pontos concentrados prÃ³ximos Ã  linha diagonal")
    print(f"   âœ… Modelo consegue capturar a tendÃªncia geral")
else:
    print(f"   âš ï¸ Pontos muito espalhados da linha diagonal")
    print(f"   âš ï¸ Modelo tem dificuldade para prever com precisÃ£o")

print(f"\n2. ANÃLISE DE RESÃDUOS:")
residuals = y_test - y_pred
residual_mean = np.mean(residuals)
if abs(residual_mean) < 0.1:
    print(f"   âœ… ResÃ­duos centrados em zero (sem viÃ©s)")
else:
    print(f"   âš ï¸ ResÃ­duos deslocados (viÃ©s de {residual_mean:.3f})")

residual_pattern = np.corrcoef(y_pred, residuals)[0,1]
if abs(residual_pattern) < 0.1:
    print(f"   âœ… ResÃ­duos distribuÃ­dos aleatoriamente")
else:
    print(f"   âš ï¸ PadrÃ£o detectado nos resÃ­duos")

print(f"\n3. DISTRIBUIÃ‡ÃƒO DOS ERROS:")
residual_std = np.std(residuals)
print(f"   â€¢ Desvio padrÃ£o dos erros: {residual_std:.3f}")
if residual_std < 0.8:
    print(f"   âœ… Erros pequenos e consistentes")
else:
    print(f"   âš ï¸ Erros grandes e variÃ¡veis")

print(f"\n4. CARACTERÃSTICAS MAIS INFLUENTES:")
top_features = feature_importance[:3]
for i, (feature, weight) in enumerate(top_features):
    impact = "forte" if abs(weight) > 0.15 else "moderado" if abs(weight) > 0.08 else "fraco"
    direction = "positivo" if weight > 0 else "negativo"
    print(f"   â€¢ {feature}: impacto {impact} {direction}")

print(f"\nğŸ’¡ INTERPRETAÃ‡ÃƒO PRÃTICA:")

alcohol_weight = next((w for f, w in feature_importance if 'alcohol' in f), 0)
if alcohol_weight > 0.1:
    print(f"   ğŸ· Vinhos com maior teor alcoÃ³lico tendem a ter melhor qualidade")

volatile_acidity_weight = next((w for f, w in feature_importance if 'volatile acidity' in f), 0)
if volatile_acidity_weight < -0.05:
    print(f"   ğŸ§ª Alta acidez volÃ¡til prejudica significativamente a qualidade")

sulphates_weight = next((w for f, w in feature_importance if 'sulphates' in f), 0)
if sulphates_weight > 0.05:
    print(f"   ğŸ“Š Sulfatos em quantidade adequada melhoram a qualidade")

print(f"\nğŸ¯ QUALIDADE DO MODELO:")
if r2 > 0.6:
    print(f"   ğŸŸ¢ EXCELENTE: Modelo explica {r2:.1%} da variaÃ§Ã£o")
elif r2 > 0.4:
    print(f"   ğŸŸ¡ BOM: Modelo explica {r2:.1%} da variaÃ§Ã£o")
elif r2 > 0.2:
    print(f"   ğŸŸ  REGULAR: Modelo explica {r2:.1%} da variaÃ§Ã£o")
else:
    print(f"   ğŸ”´ FRACO: Modelo explica apenas {r2:.1%} da variaÃ§Ã£o")

if mae < 0.6:
    print(f"   âœ… Erro mÃ©dio baixo: {mae:.2f} pontos")
elif mae < 1.0:
    print(f"   ğŸŸ¡ Erro mÃ©dio moderado: {mae:.2f} pontos")
else:
    print(f"   âš ï¸ Erro mÃ©dio alto: {mae:.2f} pontos")

print(f"\n" + "="*60) 